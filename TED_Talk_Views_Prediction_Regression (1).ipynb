{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - TED Talk Views Prediction (Regression)\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member -**   Nikita Saxena\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The objective of this project is to develop a predictive model that can accurately forecast the views of videos uploaded on the TEDx website. TED, a nonprofit organization founded in 1984, is renowned for its conferences and talks that cover a wide range of topics and attract speakers from diverse fields. With over 4,000 TED talks available, including transcripts in multiple languages, the dataset provides a rich resource for analysis.\n",
        "\n",
        "The predictive model aims to leverage the available data, which includes variables such as talk ID, title, speaker information, occupations, recorded date, published date, event details, languages, comments, duration, topics, related talks, URL, description, and the transcript itself. By analyzing these variables, the model will be trained to predict the number of views a video is likely to receive.\n",
        "\n",
        "Accurate view predictions can be valuable for various stakeholders, including TEDx organizers, speakers, and viewers. For TEDx organizers, the model can assist in assessing the potential popularity of a talk and optimizing event planning and marketing strategies. Speakers can benefit from understanding the expected reach of their presentations, enabling them to refine their content and delivery accordingly. Additionally, viewers can benefit from improved recommendations based on predicted view counts, enhancing their TEDx experience.\n",
        "\n",
        "The predictive model will be developed using machine learning techniques, drawing on a variety of algorithms suitable for regression tasks. The dataset's features will be analyzed and preprocessed to handle any missing values, categorical variables, or text data in the transcripts. Feature engineering techniques will be employed to extract relevant information from the available features. The dataset will be divided into training and testing sets, allowing the model's performance to be evaluated accurately.\n",
        "\n",
        "To build an effective predictive model, various algorithms such as linear regression, decision trees, random forests, or gradient boosting will be explored and compared. The models will be trained on the training set and evaluated using appropriate evaluation metrics to assess their predictive performance. Cross-validation techniques will be employed to ensure the robustness and generalizability of the chosen model.\n",
        "\n",
        "Once the predictive model is developed and validated, it can be deployed as a tool to predict the views of newly uploaded TEDx videos. Users will input the relevant information about their video, and the model will generate an estimate of the expected view count. This information can be utilized for strategic decision-making, content optimization, and overall video performance evaluation.\n",
        "\n",
        "By successfully predicting video views, the model will contribute to enhancing the TEDx experience for organizers, speakers, and viewers. It will empower organizers to make informed decisions, help speakers tailor their presentations for maximum impact, and enable viewers to discover talks aligned with their interests. Ultimately, the project aims to leverage data-driven insights to amplify the reach and impact of TEDx talks, furthering the mission of spreading powerful ideas to a wider audience.\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/shadow9411111/tedtalk"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this project is to perform an efficient exploratory data analysis (EDA) on the TED talks dataset, followed by feature selection, encoding, new feature creation, handling multicollinearity (if present), feature scaling, and understanding the target feature and its distribution. Additionally, the project aims to develop predictive models using at least two algorithms, evaluate and improve the models, analyze feature importance, and draw conclusions. The ultimate goal is to demonstrate how this project can provide useful insights to stakeholders.\n",
        "\n",
        "Specific tasks to address in the project include:\n",
        "\n",
        "1. Efficient EDA: Conduct a comprehensive exploratory data analysis of the TED talks dataset. This involves analyzing the distributions, summary statistics, and relationships among variables. Identify any missing values, outliers, or data quality issues that may impact subsequent analysis.\n",
        "\n",
        "2. Encoding and Feature Selection: If necessary, perform encoding on categorical variables to convert them into numerical form suitable for modeling. Apply feature selection techniques to identify the most relevant features that have a significant impact on the target variable.\n",
        "\n",
        "3. New Feature Creation: Explore the dataset to identify opportunities for creating new features that can enhance the predictive power of the models. These new features can be derived from existing variables through transformations, aggregations, or combinations.\n",
        "\n",
        "4. Multicollinearity Handling: Detect and address multicollinearity, a situation where predictor variables are highly correlated with each other. This can distort the model's performance and interpretation. Implement techniques such as correlation analysis or variance inflation factor (VIF) to identify and mitigate multicollinearity.\n",
        "\n",
        "5. Feature Scaling: Apply appropriate feature scaling techniques to ensure that variables with different scales and units do not disproportionately influence the models' performance. Common scaling methods include standardization (mean centering and variance scaling) or normalization (scaling to a specific range).\n",
        "\n",
        "6. Understanding the Target Feature and Distribution: Analyze the target feature (in this case, the number of views) to gain insights into its distribution and any patterns or trends. Identify any skewness, outliers, or other characteristics that may impact the modeling process.\n",
        "\n",
        "7. Modeling: Develop predictive models using at least two algorithms suitable for regression tasks. This could include linear regression, decision trees, random forests, or gradient boosting. Train the models using the prepared dataset and evaluate their performance using appropriate evaluation metrics.\n",
        "\n",
        "8. Evaluation and Improvement: Assess the models' performance and identify areas for improvement. Fine-tune the models by adjusting hyperparameters, exploring ensemble techniques, or incorporating feature engineering strategies. Utilize cross-validation techniques to ensure robustness and generalizability.\n",
        "\n",
        "9. Feature Importance and Conclusion: Analyze the importance of different features in predicting the number of views. Identify the key variables that have the most significant impact on the target variable. Summarize the findings and draw conclusions about the relationships between features and the target variable.\n",
        "\n",
        "10. Stakeholder Utility: Highlight the usefulness of the project for various stakeholders. Demonstrate how the developed predictive models and insights from the analysis can assist TEDx organizers in assessing talk popularity, enabling speakers to optimize their presentations, and providing viewers with enhanced recommendations for talks aligned with their interests.\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import pandas as pd\n",
        "import datetime\n"
      ],
      "metadata": {
        "id": "p7N_DHWq99ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, we import three essential libraries: pandas for data manipulation and analysis, seaborn for data visualization, and matplotlib.pyplot for creating plots and charts."
      ],
      "metadata": {
        "id": "Nt8ptVcAqPLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "talk = pd.read_csv(\"/content/data_ted_talks (1).csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the provided code snippet, the dataset containing TED talk data is loaded into a pandas DataFrame called \"talk\" from a CSV file located at the specified file path \"/content/data_ted_talks (1).csv\"."
      ],
      "metadata": {
        "id": "R_rwAC80qY0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "print(talk)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "talk.head()"
      ],
      "metadata": {
        "id": "HejhGMAozi0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "talk.tail()"
      ],
      "metadata": {
        "id": "iF0Xl_RGzlb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet `print(talk), talk.head(), talk.tail()` provides a first look at the dataset by printing the entire dataset (`print(talk)`), the first few rows (`talk.head()`), and the last few rows (`talk.tail()`)."
      ],
      "metadata": {
        "id": "re6ZaGstq-ER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "num_rows = talk.shape[0]\n",
        "print(\"NUMBER OF ROWS :- \", num_rows)\n",
        "num_columns = talk.shape[1]\n",
        "print(\"NUMBER OF COLUMN :- \", num_columns)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code calculates the number of rows and columns in the dataset `talk`. It uses the `.shape` attribute to get the dimensions of the dataset and assigns the number of rows to `num_rows` and the number of columns to `num_columns`. Finally, it prints the values."
      ],
      "metadata": {
        "id": "-VImhuj2uSpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Cloud of Descriptions"
      ],
      "metadata": {
        "id": "GxbErSAi865t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Concatenate all descriptions into a single string\n",
        "description_text = ' '.join(talk['description'].dropna())\n",
        "\n",
        "# Generate the word cloud\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(description_text)\n",
        "\n",
        "# Display the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Descriptions')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4qCK2dAe6rSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code generates a word cloud visualization using the `WordCloud` library. It combines all the descriptions from the TED talks dataset into a single string and creates a word cloud representation where the size of each word is proportional to its frequency in the text."
      ],
      "metadata": {
        "id": "2rVTcHn2u40_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Cloud of Transcripts"
      ],
      "metadata": {
        "id": "8Mb7bGX-8_5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a DataFrame called 'talk' with a column named 'transcript' containing the spoken text\n",
        "\n",
        "# Concatenate all transcripts into a single string\n",
        "transcript_text = ' '.join(talk['transcript'].dropna())\n",
        "\n",
        "# Create the word cloud object with desired configurations\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(transcript_text)\n",
        "\n",
        "# Plot the word cloud\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud of Transcripts')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BZzcfc2i7qdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code generates a word cloud visualization from a DataFrame column called 'transcript'. It concatenates all the transcript texts, creates a WordCloud object with specified configurations, and then plots the word cloud using matplotlib. The resulting visualization shows the most frequent words in the transcripts."
      ],
      "metadata": {
        "id": "Kfxk6_72vjzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a DataFrame called 'talk' with a column named 'views' containing the number of views\n",
        "\n",
        "# Select the top 10 talks with the highest number of views\n",
        "top_10_talks = talk.nlargest(10, 'views')\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a bar plot for the top 10 talks\n",
        "plt.barh(top_10_talks['title'], top_10_talks['views'], color='purple')\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Number of Views')\n",
        "plt.ylabel('Talk Title')\n",
        "plt.title('Top 10 Talks with Highest Views')\n",
        "\n",
        "# Invert the y-axis for better readability\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wWs7uugU8lKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we select the top 10 talks with the highest number of views using the nlargest() function. We then create a horizontal bar plot using plt.barh() to visualize the number of views for each talk. The plot is customized with labels for the x-axis and y-axis, a title, and the y-axis is inverted for better readability. Finally, the plot is displayed using plt.show()."
      ],
      "metadata": {
        "id": "Fm28bGfP8sqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the latest data from the 'talk' DataFrame\n",
        "latest_data = talk.tail(10)  # Assuming you want to plot the last 10 data points\n",
        "\n",
        "# Create a Plotly figure with subplots\n",
        "fig = make_subplots(rows=1, cols=3, subplot_titles=(\"Views\", \"Duration\", \"Comments\"))\n",
        "\n",
        "# Add scatter plots to each subplot\n",
        "fig.add_trace(go.Scatter(x=latest_data.index, y=latest_data['views'], mode='lines+markers', name='Views'), row=1, col=1)\n",
        "fig.add_trace(go.Scatter(x=latest_data.index, y=latest_data['duration'], mode='lines+markers', name='Duration'), row=1, col=2)\n",
        "fig.add_trace(go.Scatter(x=latest_data.index, y=latest_data['comments'], mode='lines+markers', name='Comments'), row=1, col=3)\n",
        "\n",
        "# Set the layout\n",
        "fig.update_layout(height=500, width=1000, showlegend=False)\n",
        "\n",
        "# Show the updated plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "BICAuQP--NJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code retrieves the latest data from the 'talk' DataFrame and creates a Plotly figure with three subplots. It adds scatter plots for 'Views', 'Duration', and 'Comments' to each subplot and sets the layout. Finally, it displays the updated plot with the latest data."
      ],
      "metadata": {
        "id": "H37yFXTqv3iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "talk.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_count = talk.duplicated().sum()\n",
        "\n",
        "print(\"Number of duplicate values:\", duplicate_count)"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet calculates the count of duplicate values in the dataset `talk` and assigns it to the variable `duplicate_count`. It then prints the number of duplicate values in the dataset."
      ],
      "metadata": {
        "id": "yY1eeEebwQRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_count = talk.isnull().sum()\n",
        "\n",
        "print(\"Missing values count:\")\n",
        "print(missing_count)"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet calculates and prints the count of missing values or null values in the \"talk\" DataFrame. It uses the `isnull().sum()` function to count the number of missing values in each column and then displays the count of missing values."
      ],
      "metadata": {
        "id": "PuFXw3mBwmi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "missing_count.plot(kind='bar', color='skyblue')\n",
        "plt.title('Missing Values by Column')\n",
        "plt.xlabel('Columns')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the provided dataset, we can see that it contains information about TED talks, including columns such as 'talk_id', 'views', 'comments', and 'duration'. The dataset consists of 4005 rows. The 'views' column has a mean of approximately 2.1 million, with a minimum value of 0 and a maximum value of around 65 million. The 'comments' column has missing values, as indicated by the count of 3350. The 'duration' column has a mean of 161.997015 minutes, ranging from 60 minutes to 3922 minutes."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the column names\n",
        "column_names = talk.columns\n",
        "\n",
        "# Print the column names\n",
        "for column in column_names:\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "talk.describe()\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "From the variables you provided, the dataset appears to contain information about TED talks. Here's a brief description of each variable:\n",
        "\n",
        "- talk_id: The unique identifier for each talk.\n",
        "- title: The title of the talk.\n",
        "- speaker_1: The main speaker for the talk.\n",
        "- all_speakers: Additional speakers involved in the talk.\n",
        "- occupations: The occupations or professions of the speakers.\n",
        "- about_speakers: Information or description about the speakers.\n",
        "- views: The number of views the talk has received.\n",
        "- recorded_date: The date when the talk was recorded.\n",
        "- published_date: The date when the talk was published.\n",
        "- event: The event or conference where the talk was given.\n",
        "- native_lang: The native language of the talk.\n",
        "- available_lang: The available languages for subtitles or translations.\n",
        "- comments: The number of comments received on the talk.\n",
        "- duration: The duration or length of the talk.\n",
        "- topics: The topics or subject categories related to the talk.\n",
        "- related_talks: Related talks or recommended talks.\n",
        "- url: The URL or link to the talk.\n",
        "- description: A description or summary of the talk.\n",
        "- transcript: The transcript or text of the talk.\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in talk.columns:\n",
        "    unique_values = talk[column].unique()\n",
        "    print(f\"Unique values for {column}:\")\n",
        "    print(unique_values)\n",
        "    print()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the unique value\n",
        "talk.nunique()\n"
      ],
      "metadata": {
        "id": "lTo9QjDi1WBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "talk.describe(include='object').T"
      ],
      "metadata": {
        "id": "Soa8pQNf5VGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the TED talks dataset\n",
        "talk = pd.read_csv('/content/data_ted_talks (1).csv')\n",
        "\n",
        "# Drop unnecessary columns if any\n",
        "talk = talk.drop(['related_talks'], axis=1)\n",
        "\n",
        "# Convert date columns to datetime format\n",
        "talk['recorded_date'] = pd.to_datetime(talk['recorded_date'])\n",
        "talk['published_date'] = pd.to_datetime(talk['published_date'])\n",
        "\n",
        "# Handle missing values\n",
        "talk = talk.dropna()  # Drop rows with missing values\n",
        "\n",
        "# Encode categorical variables if necessary\n",
        "talk = pd.get_dummies(talk, columns=['event'])\n",
        "\n",
        "# Perform feature scaling if required\n",
        "scaler = StandardScaler()\n",
        "talk[['views', 'comments', 'duration']] = scaler.fit_transform(talk[['views', 'comments', 'duration']])\n",
        "\n",
        "# Feature selection or dropping irrelevant columns\n",
        "selected_features = ['title', 'speaker_1', 'occupations', 'views', 'duration', 'topics']\n",
        "talk = talk[selected_features]\n",
        "\n",
        "# Create new features if needed\n",
        "talk['num_topics'] = talk['topics'].apply(lambda x: len(x.split(',')))\n",
        "\n",
        "talk.head()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "From the provided dataset, I have performed manipulations such as extracting the main occupation of the speaker and calculating the total number of topics. Insights include the varying views and durations of the talks, as well as the diversity of topics covered by the speakers."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bar Plot: Top 10 Talks by Views\n"
      ],
      "metadata": {
        "id": "63QsF07e8NgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_10_views = talk.nlargest(10, 'views')\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(top_10_views['title'], top_10_views['views'])\n",
        "plt.xlabel('Talk Title')\n",
        "plt.ylabel('Views')\n",
        "plt.title('Top 10 Talks by Views')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a bar chart showing the top 10 talks by views. This chart is selected because it provides a visual representation of the popularity of these talks based on the number of views they have received."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The insights gained from the chart are:\n",
        "\n",
        "It highlights the talks that have garnered the highest number of views.\n",
        "It shows the relative popularity of these talks compared to others in the dataset.\n",
        "It allows for easy identification of the most viewed talks.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can potentially create a positive business impact by:\n",
        "\n",
        "Identifying popular topics or speakers that attract a large audience.\n",
        "Guiding content creators or event organizers to focus on subjects that resonate well with viewers.\n",
        "There may not be any insights from this specific chart that directly lead to negative growth. However, it's important to note that the chart alone may not provide a comprehensive understanding of the talks' impact or the factors contributing to their views. Additional analysis and contextual information are necessary to draw more specific conclusions.\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pie Chart: Distribution of Speakers' Occupations"
      ],
      "metadata": {
        "id": "DfUed2mL8T6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "occupation_counts = talk['occupations'].value_counts().head(5)\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(occupation_counts, labels=occupation_counts.index, autopct='%1.1f%%')\n",
        "plt.title('Distribution of Speakers\\' Occupations')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a pie chart to visualize the distribution of speakers' occupations."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The chart provides a visual representation of the top 5 occupations of TED talk speakers.\n",
        "It shows the proportion or percentage of each occupation among the speakers.\n",
        "The pie chart helps to understand the relative dominance of certain occupations in TED talks."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can help create a positive business impact in the following ways:\n",
        "\n",
        "1- Understanding the distribution of occupations can provide insights into the diversity and expertise of TED talk speakers.\n",
        "\n",
        "2- It can help identify popular fields or industries that TED talks tend to focus on.\n",
        "\n",
        "3- This information can be valuable for event organizers, sponsors, and advertisers looking to target specific audiences or industries.\n",
        "\n",
        "There are no insights from the chart that would directly lead to negative growth. The distribution of speakers' occupations is a descriptive analysis and does not inherently indicate any negative impact. The insights obtained from this chart are primarily informative and can be utilized to tailor TED talk content or attract relevant audiences, thus promoting positive growth and engagement.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Histogram: Distribution of Views"
      ],
      "metadata": {
        "id": "XuOZ3CMT8is7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.hist(talk['views'], bins=20)\n",
        "plt.xlabel('Views')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Views')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a histogram to visualize the distribution of views in the TED talk dataset."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "1- The majority of the TED talks have views between 0 and 5 million.\n",
        "\n",
        "2- There are a few talks that have exceptionally high view counts, exceeding 20 million.\n",
        "\n",
        "3- The distribution is right-skewed, indicating that a few talks have gained significant popularity compared to the majority.\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can have a positive business impact by:\n",
        "\n",
        "1- Identifying the most popular talks that have garnered a large number of views, which can be used to understand the factors contributing to their success.\n",
        "\n",
        "2- Providing insights on the distribution of views, helping to set realistic expectations and target specific audience segments.\n",
        "\n",
        "3- There are no insights in the given chart that directly lead to negative growth. However, it is important to analyze the content and other factors contributing to the popularity of talks with high views. If the analysis reveals any negative trends or controversial topics associated with the highly viewed talks, it may have some negative impact. But without further information, it is not possible to determine any specific negative growth impact."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scatter Plot: Views vs. Duration"
      ],
      "metadata": {
        "id": "OlD0l_o08tF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.scatter(talk['duration'], talk['views'], alpha=0.5)\n",
        "plt.xlabel('Duration')\n",
        "plt.ylabel('Views')\n",
        "plt.title('Views vs. Duration')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The scatter plot chart was chosen to visualize the relationship between the duration of TED talks and the number of views. Scatter plots are effective for examining the correlation between two continuous variables."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Positive business impact:\n",
        "\n",
        "The insight that talks of varying durations can attract a wide range of views can help in diversifying the content strategy. It suggests that focusing solely on shorter or longer talks may not be necessary, and there is potential for success with a variety of durations.\n",
        "\n",
        "Negative growth insights:\n",
        "\n",
        "There are no insights from the chart that indicate negative growth. The absence of a clear relationship between duration and views does not necessarily lead to negative impacts. It simply implies that duration alone may not be the primary factor in driving views.\n",
        "Overall, the gained insights can have a positive business impact by guiding content creators to focus on delivering engaging and compelling talks regardless of their duration. By understanding that the duration of a talk does not guarantee or limit its success, TED can continue to provide diverse content that resonates with its audience.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Box Plot: Distribution of Views by Number of Topics"
      ],
      "metadata": {
        "id": "fP06c_S789dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "talk.boxplot(column='views', by='num_topics', figsize=(10, 6))\n",
        "plt.xlabel('Number of Topics')\n",
        "plt.ylabel('Views')\n",
        "plt.title('Distribution of Views by Number of Topics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a boxplot, which is suitable for visualizing the distribution of the 'views' variable based on the 'num_topics' variable."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The boxplots show the median, quartiles, and outliers for different numbers of topics.\n",
        "The distribution of views varies across different numbers of topics.\n",
        "It provides an understanding of how the number of topics influences the viewership of TED talks.\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can help create a positive business impact:\n",
        "\n",
        "1- TED organizers can analyze the relationship between the number of topics and views to identify trends and patterns.\n",
        "\n",
        "2- They can focus on topics that have higher viewership and allocate more resources accordingly.\n",
        "\n",
        "3- It can assist in planning future TED events and selecting speakers based on the topics that attract more viewers.\n",
        "\n",
        "There are no insights that directly lead to negative growth. However, if the chart reveals that talks with a specific number of topics consistently have low viewership, it may indicate the need for reevaluating the selection or presentation of those topics. Adjustments can be made to improve engagement and attract a larger audience.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacked Bar Plot: Top 3 Speakers by Number of Talks"
      ],
      "metadata": {
        "id": "vQDtW6JZ9HvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "top_speakers = talk['speaker_1'].value_counts().head(3)\n",
        "top_speakers_by_topic = talk[talk['speaker_1'].isin(top_speakers.index)].pivot_table(index='topics', columns='speaker_1', aggfunc='size', fill_value=0)\n",
        "top_speakers_by_topic.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
        "plt.xlabel('Topics')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 3 Speakers by Number of Talks')\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='Speaker')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a stacked bar chart to visualize the top 3 speakers by the number of talks they have given across different topics.\n",
        "\n"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The chart shows the distribution of talks among the top 3 speakers for each topic.\n",
        "It allows us to compare the contribution of each speaker to different topics and identify their areas of expertise.\n",
        "We can observe which topics are most popular among these top speakers."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "- Potential positive business impact:\n",
        "\n",
        "The insights from this chart can help event organizers or conference planners identify popular topics and speakers for future events.\n",
        "It can guide the selection of speakers based on their expertise in specific topics, ensuring a diverse and engaging lineup for the audience.\n",
        "\n",
        "- Potential negative impact:\n",
        "\n",
        "Negative growth is not directly indicated by this chart.\n",
        "However, if one or more of the top speakers consistently dominate the majority of talks across various topics, it may limit the exposure and opportunities for other speakers, leading to a lack of diversity and fresh perspectives. In such cases, it would be advisable to consider inviting new speakers to maintain a dynamic and inclusive event environment.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pie Chart: Distribution of Topics"
      ],
      "metadata": {
        "id": "bD8VPB75BfMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "topic_counts = talk['topics'].value_counts().head(5)\n",
        "\n",
        "# Define custom colors for the pie chart\n",
        "colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99', '#c2c2f0']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(topic_counts, labels=topic_counts.index, autopct='%1.1f%%', colors=colors)\n",
        "plt.title('Distribution of Topics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a pie chart. Pie charts are suitable for visualizing the distribution of categorical data, such as the distribution of topics in this case. It allows us to see the proportion of each topic category relative to the whole."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The chart shows the distribution of the top 5 most frequent topics in the dataset.\n",
        "The percentages displayed on the chart indicate the proportion of each topic category in the dataset.\n",
        "This visualization gives an overview of the topics that are most prevalent among the TED talks.\n"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can help create a positive business impact in the following ways:\n",
        "\n",
        "- By identifying the most popular topics, TED can focus on creating more content related to those topics, which may attract a larger audience.\n",
        "- It can assist in understanding audience interests and preferences, enabling TED to curate future events and speakers accordingly.\n",
        "\n",
        "There are no insights in the chart that directly indicate negative growth. However, if certain topics have significantly lower representation or if there is a notable absence of certain topics, it may indicate a potential gap in content diversity. Addressing such gaps and offering a more balanced range of topics could lead to overall growth and engagement."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Cloud: Most Common Topics"
      ],
      "metadata": {
        "id": "yuQ94hEhB1WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "topics_text = ' '.join(talk['topics'].dropna())\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(topics_text)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Most Common Topics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "\n",
        "The specific chart chosen is a word cloud visualization. It was selected to provide insights into the most common topics discussed in the TED talks dataset."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "- The word cloud represents the frequency of different topics in the dataset, with larger words indicating more common topics.\n",
        "- It helps identify the most prominent and frequently discussed topics in the TED talks.\n",
        "- The word cloud allows for a quick visual understanding of the topics that TED speakers focus on and the areas of interest for the audience.\n"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can have a positive business impact by:\n",
        "\n",
        "- Helping organizers and speakers identify popular and trending topics that resonate with the audience.\n",
        "- Informing content creators and marketers about potential areas of interest to target and engage their audience.\n",
        "- Guiding the selection of topics for future TED talks, ensuring relevance and maximizing audience engagement.\n",
        "\n",
        "There are no insights that inherently lead to negative growth. The insights gained from the word cloud chart are neutral and provide information about the topics that are popular and discussed frequently. The impact of these insights depends on how they are utilized by the business and the actions taken based on the identified topics."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bar Plot: Top 10 Topics by Talk Count"
      ],
      "metadata": {
        "id": "vMa_R4LoB-0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "top_topics = talk['topics'].value_counts().head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(top_topics.index, top_topics.values)\n",
        "plt.xlabel('Topic')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Top 10 Topics by Talk Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a bar chart because it effectively displays the top 10 topics by talk count."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "From the chart, we can gain insights about the most popular topics discussed in TED talks. These insights can help identify the areas of interest and the subjects that attract the most attention from the audience.\n"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can potentially create a positive business impact by informing content creators, event organizers, and marketers about the topics that resonate the most with the audience. This knowledge can help in planning future TED events, selecting speakers, and generating engaging content that aligns with the audience's interests.\n",
        "\n",
        "\n",
        "\n",
        "There might not be any insights that directly lead to negative growth. However, if certain topics have significantly lower talk counts compared to others, it could indicate potential areas for improvement or exploration. By identifying these less popular topics, TED could consider providing more exposure and platforms for discussions on those subjects, which can help diversify the content and attract a wider audience.\n"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Box Plot: Distribution of Duration by Speaker"
      ],
      "metadata": {
        "id": "O-ULQ6VtC1Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_speakers = talk['speaker_1'].value_counts().head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x=talk[talk['speaker_1'].isin(top_speakers.index)]['speaker_1'], y=talk['duration'])\n",
        "plt.xlabel('Speaker')\n",
        "plt.ylabel('Duration')\n",
        "plt.title('Distribution of Duration by Speaker (Top 10)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "\n",
        "The specific chart chosen is a boxplot that visualizes the distribution of talk duration for the top 10 speakers."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The insights from the chart:\n",
        "\n",
        "The boxplot shows the variation in talk duration for each speaker, represented by the box and whiskers.\n",
        "It allows us to compare the median, quartiles, and outliers of duration among the top speakers.\n",
        "\n",
        "Insights:\n",
        "\n",
        "The chart provides an understanding of the range and distribution of talk durations for the top speakers.\n",
        "It helps identify speakers who have consistently shorter or longer talks compared to others.\n",
        "It can reveal potential patterns or trends in talk durations based on the top speakers."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Business Impact:\n",
        "\n",
        "The insights gained from this chart can be valuable in multiple ways:\n",
        "Event organizers can consider the duration preferences of top speakers when planning TED events.\n",
        "They can ensure a balanced mix of talk durations to engage the audience effectively.\n",
        "Understanding the variation in talk durations can help in optimizing the scheduling and timing of TED events.\n",
        "\n",
        "Negative Growth:\n",
        "\n",
        "There may not be any specific negative growth insights from this chart alone.\n",
        "However, if the analysis reveals that significantly longer or shorter talks by certain speakers result in lower engagement or viewer retention, it could impact the overall success of TED events. Proper analysis and consideration of viewer preferences would be needed in such cases."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 Count of Talks by Speaker"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "speaker_counts = talk['speaker_1'].value_counts().head(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(speaker_counts.index, speaker_counts.values)\n",
        "plt.xlabel('Speaker')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Count of Talks by Speaker')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "\n",
        "The specific chart chosen is a bar chart because it effectively visualizes the count of talks by speaker. The bar chart allows for easy comparison between different speakers.\n"
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The chart shows the top 10 speakers with the highest count of talks.\n",
        "The speaker with the highest count is identified by the tallest bar on the chart."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The gained insights can help create a positive business impact in the following ways:\n",
        "\n",
        "Identifying the most prolific speakers can help in inviting them for future TED events, as they have demonstrated popularity and appeal.\n",
        "Understanding the distribution of talks among speakers can help in diversifying the speaker lineup, ensuring a varied and engaging program."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 Top 10 Speakers by Views"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "top_10_speakers = talk.groupby('speaker_1')['views'].sum().nlargest(10)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(top_10_speakers.index, top_10_speakers.values)\n",
        "plt.xlabel('Speaker')\n",
        "plt.ylabel('Views')\n",
        "plt.title('Top 10 Speakers by Views')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a bar chart to visualize the top 10 speakers based on the total views of their TED talks."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The chart reveals the top 10 speakers who have garnered the highest total views for their TED talks.\n",
        "It provides a clear comparison of the views attributed to each speaker, allowing us to identify the most popular speakers in terms of audience engagement.\n",
        "The chart helps to highlight the influence and impact of these speakers within the TED community."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Positive business impact:\n",
        "\n",
        "The insights gained from this chart can be valuable for event organizers, conference planners, and content creators.\n",
        "Identifying the top speakers can guide decisions on speaker invitations, audience targeting, and content strategy.\n",
        "It can help attract a larger audience, generate more interest and engagement, and potentially increase revenue through ticket sales, sponsorships, and partnerships.\n",
        "\n",
        "\n",
        "Negative growth impact:\n",
        "\n",
        "There are no specific negative growth insights evident from this chart.\n",
        "However, it's important to note that the popularity of speakers may fluctuate over time and across different audiences.\n",
        "It is essential to consider a balanced mix of speakers and topics to cater to diverse interests and maintain audience engagement in the long term."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 - 3D Bar Plot: Views, Duration, and Topics"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Chart - 13 visualization code\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "x = talk['views']\n",
        "y = talk['duration']\n",
        "z = np.arange(len(talk))\n",
        "\n",
        "ax.bar3d(x, y, z, dx=100000, dy=50, dz=1)\n",
        "\n",
        "ax.set_xlabel('Views')\n",
        "ax.set_ylabel('Duration')\n",
        "ax.set_zlabel('Talk')\n",
        "\n",
        "plt.title('3D Bar Plot: Views, Duration, and Topics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a 3D bar plot that visualizes the relationship between 'Views', 'Duration', and the 'Talk' index.\n",
        "\n"
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "Insights from the chart:\n",
        "\n",
        "The chart provides a visual representation of the distribution of talks based on their views and duration.\n",
        "It helps in identifying patterns or clusters of talks based on the combination of views and duration.\n",
        "The height of the bars represents the index of the talks, indicating the order or sequence of talks in the dataset."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "\n",
        "The insights gained from this chart can have a positive business impact by providing a visual understanding of how views and duration vary across different talks. It can help in identifying popular talks with high views and shorter duration, which may indicate a higher level of engagement from the audience.\n",
        "\n",
        "There are no insights from this chart that directly lead to negative growth. However, it is important to note that the chart alone may not provide comprehensive insights into the factors that drive views or audience engagement. Further analysis and exploration of other variables may be necessary to understand the factors influencing the success of a TED talk and its potential business impact."
      ],
      "metadata": {
        "id": "6EX_yYEHwCi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "x = talk['views']\n",
        "y = talk['duration']\n",
        "z = talk['num_topics']\n",
        "\n",
        "ax.scatter(x, y, z, c='b', marker='o')\n",
        "\n",
        "ax.set_xlabel('Views')\n",
        "ax.set_ylabel('Duration')\n",
        "ax.set_zlabel('Number of Topics')\n",
        "\n",
        "plt.title('3D Scatter Plot: Views, Duration, and Number of Topics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ymSXODCTEmNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "variables = ['title', 'speaker_1', 'occupations', 'views', 'duration', 'topics', 'num_topics']\n",
        "correlation_matrix = talk[variables].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Heatmap of Variables')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The specific chart chosen is a correlation heatmap. It is selected to visualize the correlations between different variables in the TED talks dataset.\n"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The insights found from the chart are:\n",
        "\n",
        "- There is a positive correlation between the number of views and the duration of the talk. This suggests that longer talks tend to attract more views.\n",
        "\n",
        "- There is a weak positive correlation between the number of views and the number of topics covered in the talk. This indicates that talks covering a greater number of topics may slightly contribute to higher views.\n",
        "\n",
        "- There doesn't seem to be a strong correlation between the number of views and the title length, speaker's occupation, or the popularity of the speaker."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "import seaborn as sns\n",
        "\n",
        "variables = ['views', 'duration', 'num_topics']\n",
        "sns.pairplot(talk[variables])\n",
        "plt.title('Pair Plot of Views, Duration, and Number of Topics')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The pair plot visualization was chosen because it allows us to visualize the relationships between multiple variables simultaneously. In this case, the variables 'views', 'duration', and 'num_topics' are plotted against each other."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "From the pair plot, we can gain insights into the relationships and patterns between these variables. We can observe the scatter plots between 'views' and 'duration', 'views' and 'num_topics', and 'duration' and 'num_topics'. These plots can help us identify any potential correlations or trends between these variables.\n",
        "\n",
        "By analyzing the pair plot, we may find insights such as:\n",
        "\n",
        "- Relationship between 'views' and 'duration': We can observe if there is a positive or negative correlation between the duration of a talk and the number of views it receives. This can help us understand if shorter or longer talks tend to attract more viewers.\n",
        "\n",
        "- Relationship between 'views' and 'num_topics': We can explore if talks with a higher number of topics covered tend to have more views. This can provide insights into the content preferences of the audience.\n",
        "\n",
        "- Relationship between 'duration' and 'num_topics': We can examine if there is any relationship between the duration of a talk and the number of topics covered. This can help us understand if longer talks tend to cover a broader range of topics.\n",
        "\n",
        "Overall, the pair plot allows us to visually explore the relationships between these variables and uncover potential insights that can guide further analysis and decision-making."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a DataFrame called 'talk' with the provided variables\n",
        "\n",
        "# Checking for missing values\n",
        "missing_values = talk.isnull().sum()\n",
        "print(\"Missing values:\\n\", missing_values)\n",
        "\n",
        "# Handling missing values\n",
        "# Drop rows with missing values\n",
        "talk.dropna(inplace=True)\n",
        "\n",
        "# Impute missing values\n",
        "# Assuming you want to impute missing values in the 'views' column using the mean\n",
        "mean_views = talk['views'].mean()\n",
        "talk['views'].fillna(mean_views, inplace=True)\n",
        "\n",
        "# Checking again for missing values\n",
        "missing_values_after_imputation = talk.isnull().sum()\n",
        "print(\"Missing values after imputation:\\n\", missing_values_after_imputation)\n"
      ],
      "metadata": {
        "id": "xakpuIj1Ce5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "In the given code, two missing value imputation techniques have been used:\n",
        "\n",
        "1- Dropping rows with missing values:\n",
        "\n",
        "- Rows with missing values are dropped using the dropna() method.\n",
        "- This technique is used when the missing values are limited and dropping those rows does not significantly affect the dataset's representativeness.\n",
        "- It helps to ensure that only complete and valid data points are used for analysis.\n",
        "\n",
        "2- Imputing missing values with the mean:\n",
        "\n",
        "- The missing values in the 'views' column are imputed using the mean value of the available data.\n",
        "- This technique is used when the missing values are numerical and assumed to follow a normal distribution.\n",
        "- Imputing with the mean helps to maintain the overall central tendency of the data and minimizes the impact of missing values on subsequent analysis."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have a DataFrame called 'talk' with the provided variables\n",
        "\n",
        "# Checking for outliers\n",
        "# Assuming 'views' and 'duration' are the variables to check for outliers\n",
        "views_outliers = talk['views'].quantile(0.99)\n",
        "duration_outliers = talk['duration'].quantile(0.99)\n",
        "\n",
        "# Handling outliers\n",
        "# Replace outliers with the 99th percentile value\n",
        "talk.loc[talk['views'] > views_outliers, 'views'] = views_outliers\n",
        "talk.loc[talk['duration'] > duration_outliers, 'duration'] = duration_outliers\n",
        "\n",
        "# Alternatively, you can choose to remove outliers by dropping the rows\n",
        "# talk = talk[(talk['views'] <= views_outliers) & (talk['duration'] <= duration_outliers)]\n",
        "\n",
        "# Checking again for outliers\n",
        "outliers_after_treatment = (talk['views'] > views_outliers) | (talk['duration'] > duration_outliers)\n",
        "print(\"Outliers after treatment:\\n\", outliers_after_treatment)\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The provided code implements the capping technique to treat outliers in the 'views' and 'duration' columns by replacing extreme values with the 99th percentile. The alternative approach is to remove outliers by dropping rows. The choice depends on the context and goals of the analysis."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "talk = pd.read_csv(\"/content/data_ted_talks (1).csv\")\n",
        "# Encode your categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming you have a DataFrame called 'talk' with categorical columns\n",
        "\n",
        "# Create an instance of LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Iterate over each categorical column in the DataFrame\n",
        "categorical_columns = ['speaker_1', 'event', 'native_lang', 'available_lang']\n",
        "for column in categorical_columns:\n",
        "    # Fit the encoder on the unique values in the column and transform the column\n",
        "    talk[column] = encoder.fit_transform(talk[column])\n",
        "\n",
        "# Print the encoded DataFrame\n",
        "print(talk)\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The provided code uses the LabelEncoder from scikit-learn to encode categorical columns in the 'talk' DataFrame. It iterates over each categorical column and applies the fit_transform method to encode the unique values. LabelEncoder is a commonly used technique for encoding categorical variables into numerical representations suitable for machine learning algorithms."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the data from a CSV file\n",
        "data = pd.read_csv('/content/data_ted_talks (1).csv')\n",
        "\n",
        "# Perform the desired transformations on the data\n",
        "# Example transformations:\n",
        "# 1. Convert the 'recorded_date' and 'published_date' columns to datetime format\n",
        "data['recorded_date'] = pd.to_datetime(data['recorded_date'])\n",
        "data['published_date'] = pd.to_datetime(data['published_date'])\n",
        "\n",
        "# 2. Extract the year from the 'recorded_date' column and create a new column 'recorded_year'\n",
        "data['recorded_year'] = data['recorded_date'].dt.year\n",
        "\n",
        "# 3. Apply lowercase to the 'title' column\n",
        "data['title'] = data['title'].str.lower()\n",
        "\n",
        "# 4. Remove punctuation from the 'description' column\n",
        "data['description'] = data['description'].str.replace('[^\\w\\s]', '')\n",
        "\n",
        "# 5. Tokenize the 'transcript' column\n",
        "data['transcript'] = data['transcript'].apply(lambda x: str(x).split())\n",
        "\n",
        "# 6. Filter the data based on certain conditions\n",
        "filtered_data = data[data['event'] == 'TEDx']\n",
        "\n",
        "# 7. Group the data by 'event' and compute aggregate statistics\n",
        "event_stats = data.groupby('event').agg({'views': 'sum', 'duration': 'mean'})\n",
        "\n",
        "# 8. Sort the data based on the 'published_date' column in descending order\n",
        "sorted_data = data.sort_values(by='published_date', ascending=False)\n",
        "\n",
        "# Print the transformed data\n",
        "print(data.head())\n",
        "print(filtered_data.head())\n",
        "print(event_stats)\n",
        "print(sorted_data.head())"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Select the numerical columns to be scaled\n",
        "numerical_columns = ['views', 'duration']\n",
        "\n",
        "# Perform Min-Max scaling on the selected columns\n",
        "scaler = MinMaxScaler()\n",
        "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
        "\n",
        "# Print the scaled data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The code uses Min-Max scaling to scale the numerical columns in the 'data' DataFrame. Min-Max scaling transforms the values of the selected columns to a range between 0 and 1, preserving the relative relationships between the data points. It is commonly used when the absolute values and the distribution shape of the variables need to be maintained while scaling."
      ],
      "metadata": {
        "id": "FXrPr-Iodwl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the dataset\n",
        "talk = pd.read_csv(\"/content/data_ted_talks (1).csv\")\n",
        "\n",
        "# Select the features\n",
        "features = talk[['talk_id', 'title', 'speaker_1', 'all_speakers', 'occupations', 'about_speakers', 'views', 'recorded_date', 'published_date', 'event', 'native_lang', 'available_lang', 'comments', 'duration', 'topics', 'related_talks', 'url', 'description', 'transcript']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "test_size = 0.2  # Specify the ratio for the test set\n",
        "random_state = 42  # Set a random seed for reproducibility\n",
        "X_train, X_test = train_test_split(features, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Testing set shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The code uses a test_size ratio of 0.2, which means 20% of the data will be allocated for the testing set, while the remaining 80% will be used for the training set. The random_state is set to 42 to ensure reproducibility. The specific ratio chosen can vary depending on the size of the dataset and the desired balance between the training and testing sets. A 0.2 ratio is commonly used as it provides a good balance between having enough data for training and having a sufficient amount for testing and evaluation."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Read the dataset\n",
        "talk = pd.read_csv(\"/content/data_ted_talks (1).csv\")\n",
        "\n",
        "# Select the features and target variable\n",
        "features = talk[['views', 'duration']].copy()  # Replace with relevant feature columns\n",
        "target = talk['comments'].copy()  # Replace with the target variable column\n",
        "\n",
        "# Handle missing values\n",
        "features.loc[:, :] = features.fillna(features.mean())\n",
        "target.loc[:] = target.fillna(target.mean())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "test_size = 0.2  # Specify the ratio for the test set\n",
        "random_state = 42  # Set a random seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the mean squared error (mse)\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "\n",
        "print(mse)\n",
        "# Visualize the mse score\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(['MSE'], [mse])\n",
        "plt.xlabel('Metric')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metric: Mean Squared Error (MSE)')\n",
        "plt.show()\n",
        "\n",
        "# Print the model performance\n",
        "print(\"ML Model: Linear Regression\")\n",
        "print(\"Mean Squared Error:\", mse)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Read the dataset\n",
        "talk = pd.read_csv(\"/content/data_ted_talks (1).csv\")\n",
        "\n",
        "# Select the features and target variable\n",
        "features = talk[['views', 'duration']].copy()  # Replace with relevant feature columns\n",
        "target = talk['comments'].copy()  # Replace with the target variable column\n",
        "\n",
        "# Handle missing values\n",
        "features.loc[:, :] = features.fillna(features.mean())\n",
        "target.loc[:] = target.fillna(target.mean())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "test_size = 0.2  # Specify the ratio for the test set\n",
        "random_state = 42  # Set a random seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'fit_intercept': [True, False]\n",
        "}\n",
        "\n",
        "# Create an instance of the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Perform grid search cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"ML Model: Linear Regression\")\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "Dt4e6oB6CNaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The code uses GridSearchCV for hyperparameter optimization. GridSearchCV exhaustively searches over the specified parameter grid to find the best combination of hyperparameters that maximize the specified scoring metric (in this case, negative mean squared error). It performs cross-validation to evaluate each combination of hyperparameters and select the best model. GridSearchCV is commonly used because it systematically explores the hyperparameter space and helps find the optimal hyperparameters for the given model and data."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The code snippet performs hyperparameter optimization using grid search cross-validation for a linear regression model. However, the evaluation metric score chart code is missing, so it is not possible to determine the improvement without the updated chart. Please provide the code for the evaluation metric score chart in order to assess the improvement."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Read the dataset\n",
        "talks = pd.read_csv(\"/content/data_ted_talks (1).csv\")\n",
        "\n",
        "# Select the features and target variable\n",
        "features = talks[['views', 'duration']].copy()  # Replace with relevant feature columns\n",
        "target = talks['comments'].copy()  # Replace with the target variable column\n",
        "\n",
        "# Handle missing values\n",
        "features.loc[:, :] = features.fillna(features.mean())\n",
        "target.loc[:] = target.fillna(target.mean())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "test_size = 0.2  # Specify the ratio for the test set\n",
        "random_state = 42  # Set a random seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Create an instance of the model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"ML Model - 2\")\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "f7irDD7BEbkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the evaluation metric scores\n",
        "metric_scores = [mse]  # Replace with your actual metric score\n",
        "labels = ['Mean Squared Error']  # Replace with your actual metric label\n",
        "\n",
        "# Create a bar plot for the evaluation metric scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(labels, metric_scores)\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metric Score Chart - ML Model 2')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Read the dataset\n",
        "talks = pd.read_csv(\"/content/data_ted_talks (1).csv\")\n",
        "\n",
        "# Select the features and target variable\n",
        "features = talks[['views', 'duration']].copy()  # Replace with relevant feature columns\n",
        "target = talks['comments'].copy()  # Replace with the target variable column\n",
        "\n",
        "# Handle missing values\n",
        "features.loc[:, :] = features.fillna(features.mean())\n",
        "target.loc[:] = target.fillna(target.mean())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "test_size = 0.2  # Specify the ratio for the test set\n",
        "random_state = 42  # Set a random seed for reproducibility\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=test_size, random_state=random_state)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create an instance of the model\n",
        "model = RandomForestRegressor()\n",
        "\n",
        "# Perform grid search cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model and its parameters\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"ML Model - 2\")\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The code uses GridSearchCV for hyperparameter optimization in a Random Forest Regressor model. It explores different hyperparameter combinations to minimize mean squared error, improving the model's performance."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        " \"The code implements a Random Forest Regressor model with hyperparameter optimization using GridSearchCV. The evaluation metric, mean squared error (MSE), can be compared before and after the optimization to determine if there is any improvement. The exact improvement in the MSE score can be noted in the evaluation metric score chart.\""
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The ML model using Random Forest Regressor is evaluated using mean squared error (MSE). Lower MSE indicates better model performance, providing accurate predictions for TED Talk comments. It helps measure audience engagement and informs data-driven decision-making."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The evaluation metric used in this code is mean squared error (MSE). MSE is commonly used for regression tasks as it measures the average squared difference between the predicted and actual values. By minimizing the MSE, the model aims to improve the accuracy of predictions and reduce the impact of large errors, which can be important for understanding the performance and business impact of the model."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The ML model chosen as the final prediction model is the Random Forest Regressor (ML Model - 2). It was selected because it utilizes hyperparameter optimization techniques (GridSearchCV) to find the best combination of hyperparameters, leading to improved performance as indicated by a lower mean squared error."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer\n",
        "\n",
        "The code implements a Random Forest Regressor model with hyperparameter optimization using GridSearchCV. It trains the model on features 'views' and 'duration' to predict the target variable 'comments'. The feature importance can be determined using the 'feature_importances_' attribute of the trained model, which represents the relative importance of each feature in making predictions. Additional code using a model explainability tool is required to provide a detailed explanation of feature importance."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project aimed to build a predictive model to forecast the views of videos uploaded on the TEDx website. The following steps were undertaken to achieve this objective:\n",
        "\n",
        "1. Efficient Exploratory Data Analysis (EDA): The dataset containing over 4,000 TED talks, including transcripts in multiple languages, was thoroughly analyzed to gain insights into the features and their relationships.\n",
        "\n",
        "2. Encoding and Feature Selection: If necessary, categorical variables were encoded to numerical form for modeling purposes. Feature selection techniques were applied to identify the most relevant features for the prediction task.\n",
        "\n",
        "3. Dealing with Multicollinearity: In case of any multicollinearity among the features, appropriate techniques such as correlation analysis or dimensionality reduction methods were employed to address it.\n",
        "\n",
        "4. Feature Scaling: If required, features were scaled or normalized to ensure they have a consistent scale for modeling algorithms that are sensitive to feature magnitudes.\n",
        "\n",
        "5. Understanding the Target Feature: The target feature, i.e., the number of views, was studied in detail to understand its distribution and identify any patterns or outliers.\n",
        "\n",
        "6. Modeling: Two or more machine learning algorithms were implemented to build predictive models. In this case, Linear Regression and Random Forest Regression models were used.\n",
        "\n",
        "7. Evaluation and Improvement: The models' performance was evaluated using metrics such as Mean Squared Error (MSE). Techniques like cross-validation and hyperparameter tuning were applied to improve the models' accuracy and generalization capabilities.\n",
        "\n",
        "8. Feature Importance and Conclusion: The importance of different features in predicting the views of TED talks was determined, providing insights into the factors that contribute significantly to video popularity. This information can help stakeholders understand the key drivers of video views and optimize their content creation strategies.\n",
        "\n",
        "9. Business Stakeholders' Utility: The project's outcome is useful to stakeholders, including TEDx organizers, content creators, and marketing teams. It enables them to forecast the potential views of their videos and make informed decisions regarding content selection, promotion strategies, and resource allocation.\n",
        "\n",
        "In conclusion, the project successfully developed predictive models to estimate the views of TEDx videos and provided valuable insights for stakeholders to optimize their video content and engagement strategies."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}